{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create a runnable with the @chain decorator\n",
    "### LangChain Expression Language (LCEL)\n",
    "\n",
    "---\n",
    "\n",
    "Alejandro Ricciardi (Omegapy)  \n",
    "created date: 01/21/2024   \n",
    "[GitHub](https://github.com/Omegapy)  \n",
    "\n",
    "Credit: [LangChain](https://python.langchain.com/docs/expression_language/) \n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6995d0d19b9f7be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Projects Description:  \n",
    "**LangChain** is a framework for developing applications powered by language models. \n",
    "\n",
    "**In this project:**  \n",
    "I explore:\n",
    "- @chain: \n",
    "The concept of decoration, ```@chain```, to arbitrary function.\n",
    "- Chain Memory - Add message history:\n",
    "The ```RunnableWithMessageHistory``` class implements message history to certain types of chains.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<b style=\"font-size:15;\">\n",
    "⚠️ This project requires an OpenAi key.\n",
    "</b>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7336166b4c5b685"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Project Map:\n",
    "- [API Key](#api-key)\n",
    "- [@Chain](#chain)\n",
    "- [Chain Memory - Add message history](#chain-memory---add-message-history)\n",
    "\n",
    "        \n",
    "- []()\n",
    "    \n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b031be154d23f43e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API Key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44b564d380f5232e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.environ.get(\"OPEN_AI_KEY\")\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:45.914169600Z",
     "start_time": "2024-01-21T14:00:45.908546100Z"
    }
   },
   "id": "d797f6c9f8eeedfd",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98d7b5f9852619f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## @Chain\n",
    "\n",
    "Arbitrary function can be turn into a chain by adding a ```@chain``` decorator.  \n",
    "This is functionally equivalent to wrapping in a [RunnableLambda - Run Custom Functions](https://python.langchain.com/docs/expression_language/how_to/functions).\n",
    "\n",
    "This will have the benefit of improved observability by tracing your chain correctly.  \n",
    "Any calls to runnables inside this function will be traced as nested children.\n",
    "It will also allow you to use this as any other runnable, compose it in chain, etc.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9e700e70642042"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:46.331800100Z",
     "start_time": "2024-01-21T14:00:45.913167600Z"
    }
   },
   "id": "173b9e2b0c968dbb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"What is the subject of this joke: {joke}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:46.339023800Z",
     "start_time": "2024-01-21T14:00:46.332800300Z"
    }
   },
   "id": "d8a1b3242ae64ec1",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Arbitrary Function (Custom Chain)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c21ffaa3ea4033"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    prompt_val1 = prompt1.invoke({\"topic\": text})\n",
    "    output1 = ChatOpenAI().invoke(prompt_val1)\n",
    "    parsed_output1 = StrOutputParser().invoke(output1)\n",
    "    chain2 = prompt2 | ChatOpenAI() | StrOutputParser()\n",
    "    return chain2.invoke({\"joke\": parsed_output1})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:46.358411800Z",
     "start_time": "2024-01-21T14:00:46.336023500Z"
    }
   },
   "id": "47b59a40ee5da014",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The ```custom_chain``` is now a runnable, meaning you will need to use ```invoke```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a853c9c0b59b65"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'The subject of this joke is bears.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_chain.invoke(\"bears\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:49.302249Z",
     "start_time": "2024-01-21T14:00:46.356413Z"
    }
   },
   "id": "1cff9a77b3f9e2bd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you check out your LangSmith traces, you should see a ```custom_chain``` trace in there, with the calls to OpenAI nested underneath"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fd552896e154b13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e49e414d921830e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Chain Memory - Add message history\n",
    "\n",
    "The ```RunnableWithMessageHistory``` let’s us add message history to certain types of chains.\n",
    "\n",
    "Specifically, it can be used for any Runnable that takes as input one of\n",
    "- a sequence of BaseMessage\n",
    "- a dict with a key that takes a sequence of ```BaseMessage```\n",
    "- a dict with a key that takes the latest message(s) as a string or sequence of ```BaseMessage```, and a separate key that takes historical messages\n",
    "And returns as output one of\n",
    "- a string that can be treated as the contents of an ```AIMessage```\n",
    "- a sequence of ```BaseMessage```\n",
    "- a dict with a key that contains a sequence of ```BaseMessage```\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "decd2a967e9d33a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup\n",
    "\n",
    "I will use [Redis](https://redis.io/) to store the chat message histories and OpenAi models.  \n",
    "Dependencies:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40b5c897c7561f24"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain redis openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:00:51.131801700Z",
     "start_time": "2024-01-21T14:00:49.301249Z"
    }
   },
   "id": "d4be619223ce3885",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import getpass\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:01:24.782678800Z",
     "start_time": "2024-01-21T14:01:16.963741900Z"
    }
   },
   "id": "b5e4de0c8565c190",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start a local Redis Stack server if we don’t have an existing Redis deployment to connect to:\n",
    "\n",
    "- You need to install [docker](https://docs.docker.com/get-started/overview/) in your desktop: [Install Docker Desktop on Windows](https://docs.docker.com/desktop/install/windows-install/)\n",
    "Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker's methodologies for shipping, testing, and deploying code, you can significantly reduce the delay between writing code and running it in production."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f30e2fcc28041f5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "docker: request returned Internal Server Error for API route and version http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/create, check if the server supports the requested API version.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:01:29.208365400Z",
     "start_time": "2024-01-21T14:01:29.117824100Z"
    }
   },
   "id": "1ee6684b8293851c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:01:05.069109500Z",
     "start_time": "2024-01-21T14:01:05.028963500Z"
    }
   },
   "id": "215666b4fa44506e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:01:05.069109500Z",
     "start_time": "2024-01-21T14:01:05.031559600Z"
    }
   },
   "id": "32a247cac2803b71",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
