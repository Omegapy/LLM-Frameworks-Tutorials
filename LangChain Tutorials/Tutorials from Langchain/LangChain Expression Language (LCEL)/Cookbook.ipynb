{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdbc446c67cbff3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Cookbook\n",
    "### LangChain Expression Language (LCEL)\n",
    "\n",
    "---\n",
    "\n",
    "Alejandro Ricciardi (Omegapy)  \n",
    "created date: 01/21/2024   \n",
    "[GitHub](https://github.com/Omegapy)  \n",
    "\n",
    "Credit: [LangChain](https://python.langchain.com/docs/expression_language/)\n",
    "\n",
    "<br>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a75bcdded142ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Projects Description:  \n",
    "**LangChain** is a framework for developing applications powered by language models. \n",
    "\n",
    "**In this project:**  I explore example of code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the [Prompt + LLM](https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser) section is a good place to start.\n",
    "\n",
    "<p></p>\n",
    "<b style=\"font-size:15;\">\n",
    "⚠️ This project requires an OpenAI key.\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127f7c829b789d1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Project Map:  \n",
    "- [API Keys](#api-keys)  \n",
    "- [Prompt + LLM)](#prompt--llm)\n",
    "    - [PromptTemplate + LLM](#prompttemplate--llm) \n",
    "        - [Base Example](#base-example-prompttemplate--llm)\n",
    "        - [Attaching Stop Sequences](#attaching-stop-sequences)\n",
    "        - [Attaching Function Call information](#attaching-function-call-information)\n",
    "    - [PromptTemplate + LLM + OutputParser](#prompttemplate--llm--outputparser)\n",
    "        - [Base Example](#base-example-prompttemplate--llm--outputparser)\n",
    "        - [Functions Output Parser](#functions-output-parser)\n",
    "    - [Simplifying input](#simplifying-input)\n",
    "- [RAG](#rag)\n",
    "    - [Base Example](#base-example-rag)\n",
    "    - [Conversational Retrieval Chain (chat_message_history)](#conversational-retrieval-chain-chat_message_history)\n",
    "        - [Base Example](#base-example-conversational-retrieval-chain)\n",
    "        - [With Memory and returning source documents](#with-memory-and-returning-source-documents)\n",
    "- [Multiple chains](#multiple-chains)\n",
    "    - [Base Example](#base-example-multiple-chains)\n",
    "        - [Using itemgetter](#using-itemgetter)\n",
    "        - [Using RunnablePassthrough()](#using-runnablepassthrough)\n",
    "    - [Branching and Merging](#branching-and-merging)\n",
    "- [Querying a SQL DB](#querying-a-sql-db)\n",
    "    - [Installing Chinook SQL DB](#installing-chinook-sql-db)\n",
    "    - [Querying a SQL DB  Base Example](#querying-a-sql-db-base-example)\n",
    "- [Agents](#agents)\n",
    "- [Code writing (Agent Functions in Python)](#code-writing-agent-functions-in-python)\n",
    "- [Routing by semantic similarity](#routing-by-semantic-similarity)\n",
    "- [Adding memory to Chains](#adding-memory-to-chains)\n",
    "- [Adding moderation](#adding-moderation)\n",
    "- [Managing prompt size (Tokens)](#managing-prompt-size-tokens)\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b363829423a7f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37d7bff16596646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:49:17.831712400Z",
     "start_time": "2024-01-22T14:49:17.807292400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.environ.get(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc95088a1e91086",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877833bdafec82e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Prompt + LLM\n",
    "\n",
    "The most common and valuable composition is taking:\n",
    "\n",
    "```PromptTemplate``` / ```ChatPromptTemplate``` -> ```LLM``` / ```ChatModel``` -> ```OutputParser```\n",
    "\n",
    "Almost any other chains you build will use this building block.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76182e9353e5e9a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### PromptTemplate + LLM\n",
    "\n",
    "The simplest composition is just combining a prompt and model to create a chain that takes user input, adds it to a prompt, passes it to a model, and returns the raw model output.\n",
    "\n",
    "Note, you can mix and match PromptTemplate/ChatPromptTemplates and LLMs/ChatModels as you like here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c6f5b050131d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Base Example (PromptTemplate + LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aba51745d0aad5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T23:12:00.386860900Z",
     "start_time": "2024-01-21T23:11:58.286112Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's a bear-related joke for you:\\n\\nWhy don't bears wear shoes?\\n\\nBecause they already have bear feet!\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {foo}\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41e9a166f01b88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Attaching Stop Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6234afa5a37ab8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T23:14:24.588019Z",
     "start_time": "2024-01-21T23:14:23.980893900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear shoes?\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model.bind(stop=[\"\\n\"])\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e539ed84e189143",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Attaching Function Call information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a3d85705f92fe46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:16:03.277017300Z",
     "start_time": "2024-01-22T00:16:00.752539300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"setup\": \"Why don\\'t bears wear shoes?\",\\n  \"punchline\": \"Because they have bear feet!\"\\n}', 'name': 'joke'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function is a structure in the JSON (JavaScript Object Notation) format. \n",
    "# JSON is widely used for storing and exchanging data and is language-agnostic, \n",
    "# meaning it can be used in various programming languages. \n",
    "# Note that the structure and syntax closely resemble how objects and arrays are defined in JavaScript or data structures in Python.\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"joke\",\n",
    "        \"description\": \"A joke\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"setup\": {\"type\": \"string\", \"description\": \"The setup for the joke\"},\n",
    "                \"punchline\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The punchline for the joke\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"setup\", \"punchline\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "chain = prompt | model.bind(function_call={\"name\": \"joke\"}, functions=functions)\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"}, config={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc4764010aeba8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b135c3d34e58d28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### PromptTemplate + LLM + OutputParser\n",
    "We can also add in an output parser to easily transform the raw LLM/ChatModel output into a more workable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d66e5a67e72b7c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Base Example (PromptTemplate + LLM + OutputParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2934cef871a0a12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:09:35.023833600Z",
     "start_time": "2024-01-22T00:09:32.134401700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here\\'s a bear joke for you:\\n\\nWhy don\\'t bears have any money?\\n\\nBecause they always have \"koala-fications\" for the job!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf31a2c3faadf59",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Functions Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5755042301e9d998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:36:53.923076900Z",
     "start_time": "2024-01-22T00:36:52.568352200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't bears wear shoes?\",\n",
       " 'punchline': 'Because they have bear feet!'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser # the 'functions' is writen in json\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"joke\"}, functions=functions) # see functions at the beginning of the notebook\n",
    "    | JsonOutputFunctionsParser() \n",
    ")\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7dc42a4b6282ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:24:49.499980600Z",
     "start_time": "2024-01-22T00:24:47.040340700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't bears wear shoes?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output by key values\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "# Setup key\n",
    "chain = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"joke\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"setup\")\n",
    ")\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f5751f785a8dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:24:57.260511500Z",
     "start_time": "2024-01-22T00:24:55.752189300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Because they already have bear feet!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punchline Key\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"joke\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"punchline\")\n",
    ")\n",
    "\n",
    "chain.invoke({\"foo\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d572e35a204363",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964cebefd015a2c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Simplifying input\n",
    "When you specify the function to return, you may just want to parse that directly\n",
    "\n",
    "Two different code syntax how use ```RunnablePassthrough()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20c3826cad6c67b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:37:22.405383Z",
     "start_time": "2024-01-22T00:37:20.740333900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't bears like fast food?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "map_ = RunnableParallel(foo=RunnablePassthrough())\n",
    "chain = (\n",
    "    map_\n",
    "    | prompt\n",
    "    | model.bind(function_call={\"name\": \"joke\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"setup\")\n",
    ")\n",
    "\n",
    "chain.invoke(\"bears\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04732545486d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:37:41.939861300Z",
     "start_time": "2024-01-22T00:37:40.480595300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't bears wear shoes?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"foo\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(function_call={\"name\": \"joke\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"setup\")\n",
    ")\n",
    "\n",
    "chain.invoke(\"bears\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e906ed0ca203e5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a30b5fbd738934",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## RAG\n",
    "\n",
    "“retrieval-augmented generation” chain\n",
    "\n",
    "Also see RAG search in [Introduction to LangChain LCEL.ipynb](https://github.com/Omegapy/LLM-Frameworks-Tutorials/blob/1c99f3935c1b10478a4d7d2ba9b12556e88817a2/LangChain%20Tutorials/Tutorials%20from%20Langchain/Intro%20LangChain%20LCEL.ipynb)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc317294bffc53c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "### Base Example (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd9e6d3932b7f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:44:18.381160500Z",
     "start_time": "2024-01-22T00:44:18.348696900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e17845856e81f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:53:27.393121400Z",
     "start_time": "2024-01-22T00:53:26.504981700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorstore in RAM\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286278ae4450c6d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:54:00.644501400Z",
     "start_time": "2024-01-22T00:53:59.835600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough()\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e894f4ffe05bc3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:54:35.031542700Z",
     "start_time": "2024-01-22T00:54:34.199326800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison ha lavorato a Kensho.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using itemgetter\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0430d2e2761e34",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7cf08a34a4e406",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Conversational Retrieval Chain (chat_message_history)\n",
    "\n",
    "We can easily add in conversation history. This primarily means adding in chat_message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea8a8d267c5421",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Base Example (Conversational Retrieval Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "837c8c97f20aead9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:58:39.806129200Z",
     "start_time": "2024-01-22T00:58:39.771452200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ce200e2488ecf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:59:26.711436400Z",
     "start_time": "2024-01-22T00:59:26.684890200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "920370ab79aa4795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T00:59:36.439276300Z",
     "start_time": "2024-01-22T00:59:36.420184200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff3bd2eaf4ec96a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:00:25.210374800Z",
     "start_time": "2024-01-22T01:00:25.184851200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "198f52b40e504bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:00:35.254465300Z",
     "start_time": "2024-01-22T01:00:34.520464300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce2a1ebc222095b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:01:22.071809Z",
     "start_time": "2024-01-22T01:01:20.650664700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Harrison was employed at Kensho.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did harrison work?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3c53ac931421c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:01:36.850022300Z",
     "start_time": "2024-01-22T01:01:35.385170700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Harrison worked at Kensho.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did he work?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"Who wrote this notebook?\"),\n",
    "            AIMessage(content=\"Harrison\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef51526d5e136b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12ad477de1b008",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### With Memory and returning source documents\n",
    "\n",
    "This shows how to use memory with the above. For memory, we need to manage that outside at the memory. For returning the retrieved documents, we just need to pass them through all the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9317c064466fa38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:08:07.284197300Z",
     "start_time": "2024-01-22T01:08:06.368016100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea4f1c6680b98ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:08:22.819971400Z",
     "start_time": "2024-01-22T01:08:22.785280600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f3ff27a3fb80365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:08:31.977695200Z",
     "start_time": "2024-01-22T01:08:31.242689300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "# Now we calculate the standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "# Now we retrieve the documents\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "# And now we put it all together!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcfd24356acca811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:08:43.593692500Z",
     "start_time": "2024-01-22T01:08:40.880012Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='Harrison was employed at Kensho.'),\n",
       " 'docs': [Document(page_content='harrison worked at kensho')]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"where did harrison work?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "473a11ce3079d65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:09:15.640054800Z",
     "start_time": "2024-01-22T01:09:15.609727600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='where did harrison work?'),\n",
       "  AIMessage(content='Harrison was employed at Kensho.')]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the memory does not save automatically\n",
    "# This will be improved in the future\n",
    "# For now you need to save it yourself\n",
    "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5430a4b9e73197d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T01:09:34.214352100Z",
     "start_time": "2024-01-22T01:09:32.417783400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='Harrison actually worked at Kensho.'),\n",
       " 'docs': [Document(page_content='harrison worked at kensho')]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"but where did he really work?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c0abf9b7415b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5034d578d7ea7b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Multiple chains\n",
    "Runnables can easily be used to string together multiple Chains\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e397c837ef3ec9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Base Example (Multiple chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a61c6dd9eba779",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Using itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b866368c672900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:49:50.492348Z",
     "start_time": "2024-01-22T14:49:46.316341100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El país en el que se encuentra la ciudad de Honolulu, Hawái, donde nació Barack Obama, el 44º presidente de Estados Unidos, es Estados Unidos.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what country is the city {city} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"city\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"person\": \"obama\", \"language\": \"spanish\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c524f72a37830f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Using RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace4395703aca6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:50:41.200289600Z",
     "start_time": "2024-01-22T14:50:41.156504300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"generate a {attribute} color. Return the name of the color and nothing else:\"\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\"\n",
    ")\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\"\n",
    ")\n",
    "prompt4 = ChatPromptTemplate.from_template(\n",
    "    \"What is the color of {fruit} and the flag of {country}?\"\n",
    ")\n",
    "\n",
    "model_parser = model | StrOutputParser()\n",
    "\n",
    "color_generator = (\n",
    "    {\"attribute\": RunnablePassthrough()} | prompt1 | {\"color\": model_parser}\n",
    ")\n",
    "color_to_fruit = prompt2 | model_parser\n",
    "color_to_country = prompt3 | model_parser\n",
    "question_generator = (\n",
    "    color_generator | {\"fruit\": color_to_fruit, \"country\": color_to_country} | prompt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c56e1dbd62ced0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:51:11.327877100Z",
     "start_time": "2024-01-22T14:51:09.041757400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What is the color of Coral. and the flag of Comoros?')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator.invoke(\"warm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9671302ed7a806cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:51:24.073206700Z",
     "start_time": "2024-01-22T14:51:19.741202600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The color commonly associated with \"Coral\" is a shade of pink or orange. The flag of Comoros consists of four horizontal stripes of yellow, white, red, and blue, from top to bottom.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = question_generator.invoke(\"warm\")\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8a0e2bfaa669c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68da43be750c49",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Branching and Merging\n",
    "You may want the output of one component to be processed by 2 or more other components. [RunnableParallels](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableParallel.html#langchain_core.runnables.base.RunnableParallel) let you split or fork the chain so multiple components can process the input in parallel. Later, other components can join or merge the results to synthesize a final response. This type of chain creates a computation graph that looks like the following:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfac5dac6790ea09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "     Input\n",
    "      / \\\n",
    "     /   \\\n",
    " Branch1 Branch2\n",
    "     \\   /\n",
    "      \\ /\n",
    "      Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d078434b22041c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T14:56:51.849259400Z",
     "start_time": "2024-01-22T14:55:43.639480300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'While Scrum has its drawbacks, it is important to consider these cons in the context of the project and organization. Many of the perceived negatives can be mitigated with proper implementation and by addressing potential challenges.\\n\\nFor example, time and resource constraints can be managed by setting realistic expectations and ensuring that teams have the necessary resources and support. While detailed documentation may not be a primary focus in Scrum, it is still important to maintain sufficient records and documentation to track project progress and decisions.\\n\\nWhile Scrum may have limitations for large-scale projects, it can still be adapted and scaled by implementing frameworks such as Scrum of Scrums or using agile scaling frameworks like SAFe (Scaled Agile Framework) or LeSS (Large-Scale Scrum). These frameworks provide additional structure and coordination for managing large and complex initiatives.\\n\\nTo address the dependency on a skilled Scrum Master, organizations can invest in training and development programs to ensure that Scrum Masters have the necessary skills and expertise. Additionally, organizations can consider external support or consultants to provide guidance and mentorship to the Scrum Master and the team.\\n\\nWhile adaptability in Scrum can lead to scope creep, it can be managed through effective backlog management, clear prioritization, and regular communication with stakeholders. By setting clear expectations and involving stakeholders in the decision-making process, scope creep can be minimized.\\n\\nTo overcome the challenges of self-organization, organizations can invest in team building, training, and coaching to enhance collaboration, communication, and accountability within the team.\\n\\nFinally, while estimating project timelines can be challenging in Scrum, it is possible to improve accuracy by using techniques such as story points, velocity tracking, and regular retrospective sessions to reflect and adjust future sprint planning.\\n\\nIn conclusion, while Scrum has its cons, many of these challenges can be addressed through effective implementation, adaptation, and continuous improvement. By understanding the potential pitfalls and taking proactive measures to mitigate them, organizations can leverage the benefits of Scrum and achieve successful project outcomes.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner = (\n",
    "    ChatPromptTemplate.from_template(\"Generate an argument about: {input}\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    "    | {\"base_response\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "arguments_for = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List the pros or positive aspects of {base_response}\"\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "arguments_against = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List the cons or negative aspects of {base_response}\"\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_responder = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"ai\", \"{original_response}\"),\n",
    "            (\"human\", \"Pros:\\n{results_1}\\n\\nCons:\\n{results_2}\"),\n",
    "            (\"system\", \"Generate a final response given the critique\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    planner\n",
    "    | {\n",
    "        \"results_1\": arguments_for,\n",
    "        \"results_2\": arguments_against,\n",
    "        \"original_response\": itemgetter(\"base_response\"),\n",
    "    }\n",
    "    | final_responder\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"scrum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8b7591e227542",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fcde72d69a6a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Querying a SQL DB\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ada1575d5d5a8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Installing Chinook SQL DB\n",
    "\n",
    "We’ll need the Chinook sample DB for this example. There’s many places to download it from, e.g. https://database.guide/2-sample-databases-sqlite/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989201b17898f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**The Chinook Database**\n",
    "The Chinook database was created as an alternative to the Northwind database. \n",
    "It represents a digital media store, including tables for artists, albums, media tracks, invoices and customers.\n",
    "\n",
    "The Chinook database is available on [GitHub](https://github.com/lerocha/chinook-database/tree/master/ChinookDatabase). \n",
    "It’s available for various DBMSs including MySQL, SQL Server, SQL Server Compact, PostgreSQL, Oracle, DB2, and of course, SQLite.\n",
    "\n",
    "Install the Chinook Database\n",
    "You can install the Chinook database in SQLite by running the SQL script available on GitHub. \n",
    "It’s quite a large script, so you might find it easier to run it from a file.\n",
    "\n",
    "First, save the [Chinook_Sqlite.sql](https://github.com/lerocha/chinook-database/blob/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql) script to a folder/directory on your computer. That’s a direct link to the script on GitHub.\n",
    "\n",
    "Now create a database called Chinook. You can do this by connecting to SQLite with the following\n",
    "Note: Running this script creates the database tables and populates them with data.\n",
    "\n",
    "In the terminal:\n",
    "```\n",
    "sqlite3 Chinook.db \n",
    "sqlite>\n",
    "sqlite> .read Chinook_Sqlite.sql\n",
    "```\n",
    "verify that it created the database\n",
    "```\n",
    "sqlite> SELECT * FROM Artist LIMIT 10;\n",
    "1|AC/DC\n",
    "2|Accept\n",
    "3|Aerosmith\n",
    "4|Alanis Morissette\n",
    "5|Alice In Chains\n",
    "6|Antônio Carlos Jobim\n",
    "7|Apocalyptica\n",
    "8|Audioslave\n",
    "9|BackBeat\n",
    "10|Billy Cobham\n",
    "sqlite>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16a4843d757d23",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Querying a SQL DB Base Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa5563ca1c4765d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T15:05:09.003607900Z",
     "start_time": "2024-01-22T15:05:08.950714Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Based on the table schema below, write a SQL query that would answer the user's question: {schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e6006e2dbddc08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T15:05:17.416311600Z",
     "start_time": "2024-01-22T15:05:17.257968900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a738da2585a8e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:09:48.439910800Z",
     "start_time": "2024-01-22T16:09:48.381381700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///./data/Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48ce2372abb159a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:09:52.236844800Z",
     "start_time": "2024-01-22T16:09:52.190251600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58d6367ba0c0cf91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:09:56.221871200Z",
     "start_time": "2024-01-22T16:09:54.989667500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM Employee;'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_response.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89ea81f618f47fbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:10:06.237671600Z",
     "start_time": "2024-01-22T16:10:06.189829Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Based on the table schema below, question, sql query, and sql response, write a natural language response: {schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b816e8bde21b830e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:10:10.631565600Z",
     "start_time": "2024-01-22T16:10:08.397452700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are 8 employees in the database.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee60cd00766fc4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8f3d7e78471ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Agents\n",
    "You can pass a Runnable into an agent.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80fd78c2918cffc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:23:01.334531800Z",
     "start_time": "2024-01-22T16:22:59.825244600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, tool\n",
    "from langchain.agents.output_parsers import XMLAgentOutputParser\n",
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34d3d067d04b50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:23:44.635237200Z",
     "start_time": "2024-01-22T16:23:44.281743500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "806f4c0c4a44380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:23:55.783722100Z",
     "start_time": "2024-01-22T16:23:55.711137200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search things about current events.\"\"\"\n",
    "    return \"32 degrees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "155b10b5b0fb6639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:24:15.681019400Z",
     "start_time": "2024-01-22T16:24:15.643163Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tool_list = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1518b7f75a66983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:24:24.965253200Z",
     "start_time": "2024-01-22T16:24:23.083016500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/xml-agent-convo\") # https://smith.langchain.com/hub/hwchase17/xml-agent-convo?organizationId=bd3fb686-7fb6-557c-95f9-8f1d8dcb7aee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "491f2ec034c2c31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:24:50.225367Z",
     "start_time": "2024-01-22T16:24:50.174522100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Logic for going from intermediate steps to a string to pass into model\n",
    "# This is pretty tied to the prompt\n",
    "def convert_intermediate_steps(intermediate_steps):\n",
    "    log = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "        log += (\n",
    "            f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}\"\n",
    "            f\"</tool_input><observation>{observation}</observation>\"\n",
    "        )\n",
    "    return log\n",
    "\n",
    "\n",
    "# Logic for converting tools to string to go in prompt\n",
    "def convert_tools(tools):\n",
    "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a421ffd44cd7dc8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68703a03c414ddc3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Building an agent from a runnable usually involves a few things:\n",
    "\n",
    "1. Data processing for the intermediate steps. These need to represented in a way that the language model can recognize them. This should be pretty tightly coupled to the instructions in the prompt\n",
    "2. The prompt itself\n",
    "3. The model, complete with stop tokens if needed\n",
    "4. The output parser - should be in sync with how the prompt specifies things to be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a1f17d5ade1c159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:26:12.159171200Z",
     "start_time": "2024-01-22T16:26:12.099889600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: convert_intermediate_steps(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt.partial(tools=convert_tools(tool_list))\n",
    "    | model.bind(stop=[\"</tool_input>\", \"</final_answer>\"])\n",
    "    | XMLAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dac144d2093e9ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:26:19.148415Z",
     "start_time": "2024-01-22T16:26:19.092775300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1092b53858b8c1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:27:09.736799500Z",
     "start_time": "2024-01-22T16:27:05.840218900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<tool>search</tool><tool_input>weather in New York\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0m\u001b[32;1m\u001b[1;3m<final_answer>The weather in New York is 32 degrees\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in New york?',\n",
       " 'output': 'The weather in New York is 32 degrees'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in New york?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ea9dfd5cc1d4f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a5fcd96f513df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Code writing (Agent Functions in Python)\n",
    "Example of how to use LCEL to write Python code.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bba2f20e272ee21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:32:35.231936200Z",
     "start_time": "2024-01-22T16:32:35.203359200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain_experimental.utilities import PythonREPL # pip install langchain_experimental\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29f23e133b6c3b60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:32:42.129919100Z",
     "start_time": "2024-01-22T16:32:41.772218400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Write some python code to solve the user's problem. \n",
    "\n",
    "Return only python code in Markdown format, e.g.:\n",
    "\n",
    "```python\n",
    "....\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0debc0ebb037a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:33:06.563253600Z",
     "start_time": "2024-01-22T16:33:06.524845600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _sanitize_output(text: str):\n",
    "    _, after = text.split(\"```python\")\n",
    "    return after.split(\"```\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6692fc18e9c56b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:33:23.896698100Z",
     "start_time": "2024-01-22T16:33:23.865014300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dde89eecf9a4447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:33:35.474427100Z",
     "start_time": "2024-01-22T16:33:34.267194600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"whats 2 plus 2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fbfe94f8876c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65aff4b77d3e8b2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Routing by semantic similarity\n",
    "With LCEL you can easily add [custom routing logic](https://python.langchain.com/docs/expression_language/how_to/routing#using-a-custom-function) to your chain to dynamically determine the chain logic based on user input. All you need to do is define a function that given an input returns a ```Runnable```.\n",
    "\n",
    "One especially useful technique is to use embeddings to route a query to the most relevant prompt. Here’s a very simple example.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c19d8384e35a33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:40:14.494573300Z",
     "start_time": "2024-01-22T16:40:11.849690900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8adae8086306705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:40:39.176802700Z",
     "start_time": "2024-01-22T16:40:32.653020900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A black hole is a region in space where gravity is extremely strong, so strong that nothing, not even light, can escape its gravitational pull. It is formed when a massive star collapses under its own gravity, creating a point of infinite density called a singularity. The event horizon, which is the boundary of a black hole, is the point of no return beyond which anything that enters will be trapped forever. Black holes have fascinated scientists for decades, and studying them helps us understand the nature of gravity and the behavior of matter in extreme conditions.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's a black hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d033d6749baa2fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:40:24.925647600Z",
     "start_time": "2024-01-22T16:40:18.428560700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "A black hole is a region in space where gravity is extremely strong, to the point that nothing, not even light, can escape its gravitational pull. It is formed when a massive star collapses under its own gravitational force upon running out of fuel. The collapse is so intense that it forms a singularity, a point of infinite density at the center of the black hole, surrounded by an event horizon, which is the boundary beyond which nothing can escape. Black holes have fascinated scientists and are still being actively studied to better understand their properties and effects on the surrounding space.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's a black hole\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "768e60b0e0401b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:41:30.918021400Z",
     "start_time": "2024-01-22T16:41:18.605336200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MATH\n",
      "A path integral is a concept in mathematics and physics, specifically in the field of quantum mechanics. It is used to describe the behavior of quantum particles moving between two points in space and time.\n",
      "\n",
      "In simple terms, a path integral considers all possible paths that a particle can take from an initial point to a final point. Each path is assigned a weight or probability amplitude, which is determined by the action of the particle along that path. The action is a mathematical quantity that depends on the path's shape and the physical laws governing the system.\n",
      "\n",
      "To calculate a path integral, one sums up the contributions from all possible paths, taking into account their respective probability amplitudes. This summation involves integrating over all possible configurations of the particle's position and momentum at each point along the paths.\n",
      "\n",
      "The path integral concept is a powerful tool that allows us to analyze the quantum behavior of particles in a wide range of physical systems. It is widely used in quantum field theory, quantum electrodynamics, and other areas of theoretical physics.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's a path integral\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a013d5552e899e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770fba6ca55d75c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Adding memory to Chains\n",
    "This shows how to add memory to an arbitrary chain. Right now, you can use the memory classes but need to hook it up manually\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7b58b6899b4860a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:43:54.345003700Z",
     "start_time": "2024-01-22T16:43:53.971810300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99d8fd8ae5e7a7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:44:05.603667400Z",
     "start_time": "2024-01-22T16:44:05.563131700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b0a73f8ed7ad659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:44:12.252423900Z",
     "start_time": "2024-01-22T16:44:12.209050Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23b7110b944a62ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:44:45.422721500Z",
     "start_time": "2024-01-22T16:44:45.364574Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b756ad5788050b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:45:02.240589100Z",
     "start_time": "2024-01-22T16:45:01.205947800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Bob! How can I assist you today?')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"hi im bob\"}\n",
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9c1bce1c5841da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:45:46.794127600Z",
     "start_time": "2024-01-22T16:45:46.736812900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi im bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(inputs, {\"output\": response.content})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "317640e0801df1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:45:59.132751900Z",
     "start_time": "2024-01-22T16:45:58.503268700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob.')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"whats my name\"}\n",
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c645f46d7e5c79c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd6f3605571cef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Adding moderation\n",
    "This shows how to add in moderation (or other safeguards) around your LLM application.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f035bf82a1c2859d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:48:51.889763100Z",
     "start_time": "2024-01-22T16:48:51.832241200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import OpenAIModerationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1aec4cf89328ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:49:00.270119Z",
     "start_time": "2024-01-22T16:49:00.213927900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "moderate = OpenAIModerationChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7810a2cc050894e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:49:07.215163Z",
     "start_time": "2024-01-22T16:49:06.866486800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = OpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"repeat after me: {input}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc243dc9bb1f6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:50:35.463070500Z",
     "start_time": "2024-01-22T16:50:35.401371600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96f6d64decfb479d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:50:45.205281200Z",
     "start_time": "2024-01-22T16:50:43.052737200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI am an AI and do not have the capacity to feel emotions or have thoughts about my intelligence. I am simply programmed to assist and provide information to the best of my abilities.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"you are stupid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21142b8c45c2eb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:51:20.185058100Z",
     "start_time": "2024-01-22T16:51:20.136010800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "moderated_chain = chain | moderate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ccfa69272100a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:51:28.366307800Z",
     "start_time": "2024-01-22T16:51:27.946675100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Moderation, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmoderated_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myou are stupid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1780\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 1780\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   1783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32m~\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\chains\\moderation.py:94\u001b[0m, in \u001b[0;36mOpenAIModerationChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     93\u001b[0m     text \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key]\n\u001b[1;32m---> 94\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_moderate(text, results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: output}\n",
      "File \u001b[1;32m~\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Moderation, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "moderated_chain.invoke({\"input\": \"you are stupid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf8e6f8f8e6315",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[Project Map](#project-map)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580be501084ded69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "## Managing prompt size (Tokens)\n",
    "Agents dynamically call tools. The results of those tool calls are added back to the prompt, so that the agent can plan the next action. Depending on what tools are being used and how they’re being called, the agent prompt can easily grow larger than the model context window.\n",
    "\n",
    "With LCEL, it’s easy to add custom functionality for managing the size of prompts within your chain or agent. Let’s look at simple agent example that can search Wikipedia for information.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40da2a0a32ba70ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:57:47.415878300Z",
     "start_time": "2024-01-22T16:57:43.445844500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcc8362c8fa21590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:56:42.169049500Z",
     "start_time": "2024-01-22T16:56:42.100679100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.agents import AgentExecutor, load_tools\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts.chat import ChatPromptValue\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.tools.convert_to_openai import format_tool_to_openai_function\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e911e8b3195107ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:58:01.843139100Z",
     "start_time": "2024-01-22T16:58:01.758051500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "wiki = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=10_000)\n",
    ")\n",
    "tools = [wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "622c5924d1527a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:58:14.273013600Z",
     "start_time": "2024-01-22T16:58:13.922184500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9cb9b5e747e53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let’s try a many-step question without any prompt size handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffafb48a5a2d88c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:59:11.647593500Z",
     "start_time": "2024-01-22T16:58:48.203577300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `List of presidents of the United States`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of presidents of the United States\n",
      "Summary: The president of the United States is the head of state and head of government of the United States, indirectly elected to a four-year term via the Electoral College. The officeholder leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. Since the office was established in 1789, 45 men have served in 46 presidencies. The first president, George Washington, won a unanimous vote of the Electoral College. Grover Cleveland served two non-consecutive terms and is therefore counted as the 22nd and 24th president of the United States, giving rise to the discrepancy between the number of presidencies and the number of individuals who have served as president. The incumbent president is Joe Biden.The presidency of William Henry Harrison, who died 31 days after taking office in 1841, was the shortest in American history. Franklin D. Roosevelt served the longest, over twelve years, before dying early in his fourth term in 1945. He is the only U.S. president to have served more than two terms. Since the ratification of the Twenty-second Amendment to the United States Constitution in 1951, no person may be elected president more than twice, and no one who has served more than two years of a term to which someone else was elected may be elected more than once.Four presidents died in office of natural causes (William Henry Harrison, Zachary Taylor, Warren G. Harding, and Franklin D. Roosevelt), four were assassinated (Abraham Lincoln, James A. Garfield, William McKinley, and John F. Kennedy), and one resigned (Richard Nixon, facing impeachment and removal from office). John Tyler was the first vice president to assume the presidency during a presidential term, and set the precedent that a vice president who does so becomes the fully functioning president with his presidency.Throughout most of its history, American politics has been dominated by political parties. The Constitution is silent on the issue of political parties, and at the time it came into force in 1789, no organized parties existed. Soon after the 1st Congress convened, political factions began rallying around dominant Washington administration officials, such as Alexander Hamilton and Thomas Jefferson. Concerned about the capacity of political parties to destroy the fragile unity holding the nation together, Washington remained unaffiliated with any political faction or party throughout his eight-year presidency. He was, and remains, the only U.S. president never affiliated with a political party.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by age\n",
      "Summary: In this list of presidents of the United States by age, the first table charts the age of each president of the United States at the time of presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan and post-presidency timespan are calculated up to January 21, 2024.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of vice presidents of the United States\n",
      "Summary: There have been 49 vice presidents of the United States since the office was created in 1789. Originally, the vice president was the person who received the second-most votes for president in the Electoral College. But after the election of 1800 produced a tie between Thomas Jefferson and Aaron Burr, requiring the House of Representatives to choose between them, lawmakers acted to prevent such a situation from recurring. The Twelfth Amendment was added to the Constitution in 1804, creating the current system where electors cast a separate ballot for the vice presidency.The vice president is the first person in the presidential line of succession—that is, they assume the presidency if the president dies, resigns, or is impeached and removed from office. Nine vice presidents have ascended to the presidency in this way: eight (John Tyler, Millard Fillmore, Andrew Johnson, Chester A. Arthur, Theodore Roosevelt, Calvin Coolidge, Harry S. Truman, and Lyndon B. Johnson) through the president's death and one (Gerald Ford) through the president's resignation. The vice president also serves as the president of the Senate and may choose to cast a tie-breaking vote on decisions made by the Senate. Vice presidents have exercised this latter power to varying extents over the years.Before adoption of the Twenty-fifth Amendment in 1967, an intra-term vacancy in the office of the vice president could not be filled until the next post-election inauguration. Several such vacancies occurred: seven vice presidents died, one resigned and eight succeeded to the presidency. This amendment allowed for a vacancy to be filled through appointment by the president and confirmation by both chambers of the Congress. Since its ratification, the vice presidency has been vacant twice (both in the context of scandals surrounding the Nixon administration) and was filled both times through this process, namely in 1973 following Spiro Agnew's resignation, and again in 1974 after Gerald Ford succeeded to the presidency. The amendment also established a procedure whereby a vice president may, if the president is unable to discharge the powers and duties of the office, temporarily assume the powers and duties of the office as acting president. Three vice presidents have briefly acted as president under the 25th Amendment: George H. W. Bush on July 13, 1985; Dick Cheney on June 29, 2002, and on July 21, 2007; and Kamala Harris on November 19, 2021.\n",
      "The persons who have served as vice president were born in or primarily affiliated with 27 states plus the District of Columbia. New York has produced the most of any state as eight have been born there and three others considered it their home state. Most vice presidents have been in their 50s or 60s and had political experience before assuming the office. Two vice presidents—George Clinton and John C. Calhoun—served under more than one president. Ill with tuberculosis and recovering in Cuba on Inauguration Day in 1853, William R. King, by an Act of Congress, was allowed to take the oath outside the United States. He is the only vice president to take his oath of office in a foreign country.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by net worth\n",
      "Summary: The list of presidents of the United States by net worth at peak varies greatly. Debt and depreciation often means that presidents' net worth is less than $0 at the time of death. Most presidents before 1845 were extremely wealthy, especially Andrew Jackson and George Washington. \t \n",
      "Presidents since 1929, when Herbert Hoover took office, have generally been wealthier than presidents of the late nineteenth and early twentieth centuries; with the exception of Harry S. Truman, all presidents since this time have been millionaires. These presidents have often received income from autobiographies and other writing. Except for Franklin D. Roosevelt and John F. Kennedy (both of whom died while in office), all presidents beginning with Calvin Coolidge have written autobiographies. In addition, many presidents—including Bill Clinton—have earned considerable income from public speaking after leaving office.The richest president in history may be Donald Trump. However, his net worth is not precisely known because the Trump Organization is privately held.Truman was among the poorest U.S. presidents, with a net worth considerably less than $1 million. His financial situation contributed to the doubling of the presidential salary to $100,000 in 1949. In addition, the presidential pension was created in 1958 when Truman was again experiencing financial difficulties. Harry and Bess Truman received the first Medicare cards in 1966 via the Social Security Act of 1965.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by home state\n",
      "Summary: These lists give the states of primary affiliation and of birth for each president of the United States.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `Joe Biden`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Joe Biden\n",
      "Summary: Joseph Robinette Biden Jr. (  BY-dən; born November 20, 1942) is an American politician who is the 46th and current president of the United States. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009.\n",
      "Born in Scranton, Pennsylvania, Biden moved with his family to Delaware in 1953. He graduated from the University of Delaware before earning his law degree from Syracuse University. He was elected to the New Castle County Council in 1970 and to the U.S. Senate in 1972. As a senator, Biden drafted and led the effort to pass the Violent Crime Control and Law Enforcement Act and the Violence Against Women Act. He also oversaw six U.S. Supreme Court confirmation hearings, including the contentious hearings for Robert Bork and Clarence Thomas. Biden ran unsuccessfully for the Democratic presidential nomination in 1988 and 2008. In 2008, Obama chose Biden as his running mate, and he was a close counselor to Obama during his two terms as vice president. In the 2020 presidential election, Biden and his running mate, Kamala Harris, defeated incumbents Donald Trump and Mike Pence. He became the oldest president in U.S. history, and the first to have a female vice president.\n",
      "As president, Biden signed the American Rescue Plan Act in response to the COVID-19 pandemic and subsequent recession. He signed bipartisan bills on infrastructure and manufacturing. He proposed the Build Back Better Act, which failed in Congress, but aspects of which were incorporated into the Inflation Reduction Act that he signed into law in 2022. Biden appointed Ketanji Brown Jackson to the Supreme Court. He worked with congressional Republicans to resolve the 2023 United States debt-ceiling crisis by negotiating a deal to raise the debt ceiling. In foreign policy, Biden restored America's membership in the Paris Agreement. He oversaw the complete withdrawal of U.S. troops from Afghanistan that ended the war in Afghanistan, during which the Afghan government collapsed and the Taliban seized control. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia and authorizing civilian and military aid to Ukraine. During the Israel–Hamas war, Biden announced military support for Israel, and condemned the actions of Hamas and other Palestinian militants as terrorism. In April 2023, Biden announced his candidacy for the Democratic nomination in the 2024 presidential election.\n",
      "\n",
      "Page: Family of Joe Biden\n",
      "Summary: Joe Biden, the 46th and current president of the United States, has family members who are prominent in law, education, activism and politics. Biden's immediate family became the first family of the United States on his inauguration on January 20, 2021. His immediate family circle was also the second family of the United States from 2009 to 2017, when Biden was vice president. Biden's family is mostly descended from the British Isles, with most of their ancestors coming from Ireland and England, and a smaller number descending from the French.Of Joe Biden's sixteen great-great-grandparents, ten were born in Ireland. He is descended from the Blewitts of County Mayo and the Finnegans of County Louth. One of Biden's great-great-great-grandfathers was born in Sussex, England, and emigrated to Maryland in the United States by 1820.\n",
      "\n",
      "Page: Presidency of Joe Biden\n",
      "Summary: Joe Biden's tenure as the 46th president of the United States began with his inauguration on January 20, 2021. Biden, a Democrat from Delaware who previously served as vice president for two terms under president Barack Obama, took office following his victory in the 2020 presidential election over Republican incumbent president Donald Trump. Upon his inauguration, he became the oldest president in American history, breaking the record set by his predecessor Trump. Biden entered office amid the COVID-19 pandemic, an economic crisis, and increased political polarization.On the first day of his presidency, Biden made an effort to revert President Trump's energy policy by restoring U.S. participation in the Paris Agreement and revoking the permit for the Keystone XL pipeline. He also halted funding for Trump's border wall, an expansion of the Mexican border wall. On his second day, he issued a series of executive orders to reduce the impact of COVID-19, including invoking the Defense Production Act of 1950, and set an early goal of achieving one hundred million COVID-19 vaccinations in the United States in his first 100 days.Biden signed into law the American Rescue Plan Act of 2021; a $1.9 trillion stimulus bill that temporarily established expanded unemployment insurance and sent $1,400 stimulus checks to most Americans in response to continued economic pressure from COVID-19. He signed the bipartisan Infrastructure Investment and Jobs Act; a ten-year plan brokered by Biden alongside Democrats and Republicans in Congress, to invest in American roads, bridges, public transit, ports and broadband access. Biden signed the Juneteenth National Independence Day Act, making Juneteenth a federal holiday in the United States. He appointed Ketanji Brown Jackson to the U.S. Supreme Court—the first Black woman to serve on the court. After The Supreme Court overturned Roe v. Wade, Biden took executive actions, such as the signing of Executive Order 14076, to preserve and protect women's health rights nationwide, against abortion bans in Republican led states. Biden proposed a significant expansion of the U.S. social safety net through the Build Back Better Act, but those efforts, along with voting rights legislation, failed in Congress. However, in August 2022, Biden signed the Inflation Reduction Act of 2022, a domestic appropriations bill that included some of the provisions of the Build Back Better Act after the entire bill failed to pass. It included significant federal investment in climate and domestic clean energy production, tax credits for solar panels, electric cars and other home energy programs as well as a three-year extension of Affordable Care Act subsidies. Biden signed the CHIPS and Science Act, bolstering the semiconductor and manufacturing industry, the Honoring our PACT Act, expanding health care for US veterans, and the Electoral Count Reform and Presidential Transition Improvement Act. In late 2022, Biden signed the Respect for Marriage Act, which repealed the Defense of Marriage Act and codified same-sex and interracial marriage in the United States. In response to the debt-ceiling crisis of 2023, Biden negotiated and signed the Fiscal Responsibility Act of 2023, which restrains federal spending for fiscal years 2024 and 2025, implements minor changes to SNAP and TANF, includes energy permitting reform, claws back some IRS funding and unspent money for COVID-19, and suspends the debt ceiling to January 1, 2025. Biden established the American Climate Corps and created the first ever White House Office of Gun Violence Prevention. On September 26, 2023, Joe Biden visited a United Auto Workers picket line during the 2023 United Auto Workers strike, making him the first US president to visit one.\n",
      "The foreign policy goal of the Biden administration is to restore the US to a \"position of trusted leadership\" among global democracies in order to address the challenges posed by Russia and China. In foreign policy, Biden completed the withdrawal of U.S. military forces from Afghanistan, declaring an end to nation-building efforts and shifting U.S. foreign policy toward strategic competition with China and, to a lesser extent, Russia. However, during the withdrawal, the Afghan government collapsed and the Taliban seized control, leading to Biden receiving bipartisan criticism. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia as well as providing Ukraine with over $100 billion in combined military, economic, and humanitarian aid. Biden also approved a raid which led to the death of Abu Ibrahim al-Hashimi al-Qurashi, the leader of the Islamic State, and approved a drone strike which killed Ayman Al Zawahiri, leader of Al-Qaeda. Biden signed AUKUS, an international security alliance, together with Australia and the United Kingdom. Biden called for the expansion of NATO with the addition of Finland and Sweden, and rallied NATO allies in support of Ukraine. During the 2023 Israel–Hamas war, Biden condemned Hamas and other Palestinian militants as terrorism and announced American military support for Israel; Biden also showed his support and sympathy towards Palestinians affected by the war, sent humanitarian aid, and brokered a four-day temporary pause and hostage exchange.\n",
      "Biden began his term with over 50% approval ratings; however, these fell significantly after the withdrawal from Afghanistan and remained low as the country experienced high inflation and rising gas prices. His age and mental fitness have also been a subject of discussion.\n",
      "\n",
      "Page: Cabinet of Joe Biden\n",
      "Summary: Joe Biden assumed office as President of the United States on January 20, 2021. The president has the authority to nominate members of his Cabinet to the United States Senate for confirmation under the Appointments Clause of the United States Constitution.\n",
      "Before confirmation and during congressional hearings, a high-level career member of an executive department heads this pre-confirmed cabinet on an acting basis. The Cabinet's creation was part of the transition of power following the 2020 United States presidential election.\n",
      "In addition to the 15 heads of executive departments, there are 10 Cabinet-level officials. Biden altered his cabinet structure, elevating the chair of the Council of Economic Advisers, director of the Office of Science and Technology Policy and ambassador to the United Nations as Cabinet-level positions. Biden initially removed the director of the Central Intelligence Agenc\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `Delaware`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Delaware\n",
      "Summary: Delaware (  DEL-ə-wair) is a state in the northeast and Mid-Atlantic regions of the United States. It borders Maryland to its south and west, Pennsylvania to its north, New Jersey to its northeast, and the Atlantic Ocean to its east. The state's name derives from the adjacent Delaware Bay, which in turn was named after Thomas West, 3rd Baron De La Warr, an English nobleman and the Colony of Virginia's first colonial-era governor.Delaware occupies the northeastern portion of the Delmarva Peninsula, and some islands and territory within the Delaware River. It is the 2nd smallest and 6th least populous state, but also the 6th most densely populated. Delaware's most populous city is Wilmington, and the state's capital is Dover, the 2nd most populous city in Delaware. The state is divided into three counties, the fewest number of counties of any of the 50 U.S. states; from north to south, the three counties are: New Castle County, Kent County, and Sussex County.\n",
      "The southern two counties, Kent and Sussex counties, historically have been predominantly agrarian economies. New Castle is more urbanized and is considered part of the Delaware Valley metropolitan statistical area that surrounds and includes Philadelphia, the nation's 6th most populous city. Delaware is considered part of the Southern United States by the U.S. Census Bureau, but the state's geography, culture, and history are a hybrid of the Mid-Atlantic and Northeastern regions of the country.Before Delaware coastline was explored and developed by Europeans in the 16th century, the state was inhabited by several Native Americans tribes, including the Lenape in the north and Nanticoke in the south. The state was first colonized by Dutch traders at Zwaanendael, near present-day Lewes, Delaware, in 1631.\n",
      "Delaware was one of the Thirteen Colonies that participated in the American Revolution and American Revolutionary War, in which the American Continental Army, led by George Washington, defeated the British, ended British colonization and establishing the United States as a sovereign and independent nation.\n",
      "On December 7, 1787, Delaware was the first state to ratify the Constitution of the United States, earning it the nickname \"The First State\".Since the turn of the 20th century, Delaware has become an onshore corporate haven whose corporate laws are deemed appealing to corporations; over half of all New York Stock Exchange-listed corporations and over three-fifths of the Fortune 500 is legally incorporated in the state.\n",
      "\n",
      "Page: Delaware City, Delaware\n",
      "Summary: Delaware City is a city in New Castle County, Delaware, United States. The population was 1,885 as of 2020. It is a small port town on the eastern terminus of the Chesapeake and Delaware Canal and is the location of the Forts Ferry Crossing to Fort Delaware on Pea Patch Island.\n",
      "\n",
      "\n",
      "\n",
      "Page: University of Delaware\n",
      "Summary: The University of Delaware (colloquially known as UD or Delaware) is a privately governed, state-assisted land-grant research university located in Newark, Delaware. UD is the largest university in Delaware. It offers three associate's programs, 148 bachelor's programs, 121 master's programs (with 13 joint degrees), and 55 doctoral programs across its eight colleges. The main campus is in Newark, with satellite campuses in Dover, Wilmington, Lewes, and Georgetown. It is considered a large institution with approximately 18,200 undergraduate and 4,200 graduate students. It is a privately governed university which receives public funding for being a land-grant, sea-grant, and space-grant state-supported research institution.UD is classified among \"R1: Doctoral Universities – Very high research activity\". According to the National Science Foundation, UD spent $186 million on research and development in 2018, ranking it 119th in the nation.  It is recognized with the Community Engagement Classification by the Carnegie Foundation for the Advancement of Teaching.UD students, alumni, and sports teams are known as the \"Fightin' Blue Hens\", more commonly shortened to \"Blue Hens\", and the school colors are Delaware blue and gold. UD sponsors 21 men's and women's NCAA Division-I sports teams and have competed in the Colonial Athletic Association (CAA) since 2001.\n",
      "\n",
      "Page: Delaware River\n",
      "Summary: The Delaware River is a major river in the Mid-Atlantic region of the United States and is the longest free-flowing (undammed) river in the Eastern United States. From the meeting of its branches in Hancock, New York, the river flows for 282 miles (454 km) along the borders of New York, Pennsylvania, New Jersey, and Delaware, before emptying into Delaware Bay.\n",
      "The river has been recognized by the National Wildlife Federation as one of the country's Great Waters and has been called the \"Lifeblood of the Northeast\" by American Rivers. Its watershed drains an area of 13,539 square miles (35,070 km2) and provides drinking water for 17 million people, including half of New York City via the Delaware Aqueduct.\n",
      "The Delaware River has two branches that rise in the Catskill Mountains of New York: the West Branch at Mount Jefferson in Jefferson, Schoharie County, and the East Branch at Grand Gorge, Delaware County. The branches merge to form the main Delaware River at Hancock, New York. Flowing south, the river remains relatively undeveloped, with 152 miles (245 km) protected as the Upper, Middle, and Lower Delaware National Scenic Rivers. At Trenton, New Jersey, the Delaware becomes tidal, navigable, and significantly more industrial. This section forms the backbone of the Delaware Valley metropolitan area, serving the port cities of Philadelphia, Camden, New Jersey, and Wilmington, Delaware. The river flows into Delaware Bay at Liston Point, 48 miles (77 km) upstream of the bay's outlet to the Atlantic Ocean between Cape May and Cape Henlopen.\n",
      "Before the arrival of European settlers, the river was the homeland of the Lenape native people. They called the river Lenapewihittuk, or Lenape River, and Kithanne, meaning the largest river in this part of the country.In 1609, the river was visited by a Dutch East India Company expedition led by Henry Hudson. Hudson, an English navigator, was hired to find a western route to Cathay (China), but his encounters set the stage for Dutch colonization of North America in the 17th century. Early Dutch and Swedish settlements were established along the lower section of the river and Delaware Bay. Both colonial powers called the river the South River (Zuidrivier), compared to the Hudson River, which was known as the North River. After the English expelled the Dutch and took control of the New Netherland colony in 1664, the river was renamed Delaware after Sir Thomas West, 3rd Baron De La Warr, an English nobleman and the Virginia colony's first royal governor, who defended the colony during the First Anglo-Powhatan War.\n",
      "\n",
      "Page: Lenape\n",
      "Summary: The Lenape (English: , , ; Lenape languages: [lənaːpe]), also called the Lenni Lenape and Delaware people, are an Indigenous people of the Northeastern Woodlands, who live in the United States and Canada.The Lenape's historical territory includes present-day northeastern Delaware, all of New Jersey, the eastern Pennsylvania regions of the Lehigh Valley and Northeastern Pennsylvania, and New York Bay, western Long Island, and the lower Hudson Valley in New York state. Today they are based in Oklahoma, Wisconsin, and Ontario.\n",
      "During the last decades of the 18th century, European settlers and the effects of the American Revolutionary War displaced most Lenape from their homelands and pushed them north and west. In the 1860s, under the Indian removal policy, the U.S. federal government relocated most Lenape remaining in the Eastern United States to the Indian Territory and surrounding regions. Lenape people currently belong to the Delaware Nation and Delaware Tribe of Indians in Oklahoma, the Stockbridge–Munsee Community in Wisconsin, and the Munsee-Delaware Nation, Moravian of the Thames First Nation, and Delaware of Six Nations in Ontario.\u001b[0mUnexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7180\\2448814465.py\", line 14, in <module>\n",
      "    agent_executor.invoke(\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\chains\\base.py\", line 162, in invoke\n",
      "    raise e\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\agents\\agent.py\", line 1376, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\agents\\agent.py\", line 1102, in _take_next_step\n",
      "    [\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\agents\\agent.py\", line 1102, in <listcomp>\n",
      "    [\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\agents\\agent.py\", line 1130, in _iter_next_step\n",
      "    output = self.agent.plan(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain\\agents\\agent.py\", line 392, in plan\n",
      "    for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2151, in stream\n",
      "    # Assemble the original indexes of the remaining inputs\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2138, in transform\n",
      "    name=config.get(\"run_name\") or self.get_name(),\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1232, in _transform_stream_with_config\n",
      "    config = ensure_config(config)\n",
      "                                ^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2102, in _transform\n",
      "    def batch(\n",
      "        ^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 770, in transform\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3695, in transform\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 780, in transform\n",
      "    ```python\n",
      "        ^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 249, in stream\n",
      "    raise e\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 233, in stream\n",
      "    for chunk in self._stream(\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 398, in _stream\n",
      "    for chunk in self.client.create(messages=message_dicts, **params):\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 271, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 648, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\_base_client.py\", line 1179, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\_base_client.py\", line 868, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\openai\\_base_client.py\", line 959, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens. However, your messages resulted in 5470 tokens (5402 in the messages, 68 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Who is the current US president? What's their home state? What's their home state's bird? What's that bird's scientific name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a943c38edb832",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d7a7916372d6e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[LangSmith trace](https://smith.langchain.com/public/60909eae-f4f1-43eb-9f96-354f5176f66f/r)\n",
    "\n",
    "Unfortunately we run out of space in our model’s context window before we the agent can get to the final answer. Now let’s add some prompt handling logic. To keep things simple, if our messages have too many tokens we’ll start dropping the earliest AI, Function message pairs (this is the model tool invocation message and the subsequent tool output message) in the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e09721dc96911ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T17:00:59.076740800Z",
     "start_time": "2024-01-22T17:00:28.259275500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `List of presidents of the United States`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of presidents of the United States\n",
      "Summary: The president of the United States is the head of state and head of government of the United States, indirectly elected to a four-year term via the Electoral College. The officeholder leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. Since the office was established in 1789, 45 men have served in 46 presidencies. The first president, George Washington, won a unanimous vote of the Electoral College. Grover Cleveland served two non-consecutive terms and is therefore counted as the 22nd and 24th president of the United States, giving rise to the discrepancy between the number of presidencies and the number of individuals who have served as president. The incumbent president is Joe Biden.The presidency of William Henry Harrison, who died 31 days after taking office in 1841, was the shortest in American history. Franklin D. Roosevelt served the longest, over twelve years, before dying early in his fourth term in 1945. He is the only U.S. president to have served more than two terms. Since the ratification of the Twenty-second Amendment to the United States Constitution in 1951, no person may be elected president more than twice, and no one who has served more than two years of a term to which someone else was elected may be elected more than once.Four presidents died in office of natural causes (William Henry Harrison, Zachary Taylor, Warren G. Harding, and Franklin D. Roosevelt), four were assassinated (Abraham Lincoln, James A. Garfield, William McKinley, and John F. Kennedy), and one resigned (Richard Nixon, facing impeachment and removal from office). John Tyler was the first vice president to assume the presidency during a presidential term, and set the precedent that a vice president who does so becomes the fully functioning president with his presidency.Throughout most of its history, American politics has been dominated by political parties. The Constitution is silent on the issue of political parties, and at the time it came into force in 1789, no organized parties existed. Soon after the 1st Congress convened, political factions began rallying around dominant Washington administration officials, such as Alexander Hamilton and Thomas Jefferson. Concerned about the capacity of political parties to destroy the fragile unity holding the nation together, Washington remained unaffiliated with any political faction or party throughout his eight-year presidency. He was, and remains, the only U.S. president never affiliated with a political party.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by age\n",
      "Summary: In this list of presidents of the United States by age, the first table charts the age of each president of the United States at the time of presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan and post-presidency timespan are calculated up to January 21, 2024.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of vice presidents of the United States\n",
      "Summary: There have been 49 vice presidents of the United States since the office was created in 1789. Originally, the vice president was the person who received the second-most votes for president in the Electoral College. But after the election of 1800 produced a tie between Thomas Jefferson and Aaron Burr, requiring the House of Representatives to choose between them, lawmakers acted to prevent such a situation from recurring. The Twelfth Amendment was added to the Constitution in 1804, creating the current system where electors cast a separate ballot for the vice presidency.The vice president is the first person in the presidential line of succession—that is, they assume the presidency if the president dies, resigns, or is impeached and removed from office. Nine vice presidents have ascended to the presidency in this way: eight (John Tyler, Millard Fillmore, Andrew Johnson, Chester A. Arthur, Theodore Roosevelt, Calvin Coolidge, Harry S. Truman, and Lyndon B. Johnson) through the president's death and one (Gerald Ford) through the president's resignation. The vice president also serves as the president of the Senate and may choose to cast a tie-breaking vote on decisions made by the Senate. Vice presidents have exercised this latter power to varying extents over the years.Before adoption of the Twenty-fifth Amendment in 1967, an intra-term vacancy in the office of the vice president could not be filled until the next post-election inauguration. Several such vacancies occurred: seven vice presidents died, one resigned and eight succeeded to the presidency. This amendment allowed for a vacancy to be filled through appointment by the president and confirmation by both chambers of the Congress. Since its ratification, the vice presidency has been vacant twice (both in the context of scandals surrounding the Nixon administration) and was filled both times through this process, namely in 1973 following Spiro Agnew's resignation, and again in 1974 after Gerald Ford succeeded to the presidency. The amendment also established a procedure whereby a vice president may, if the president is unable to discharge the powers and duties of the office, temporarily assume the powers and duties of the office as acting president. Three vice presidents have briefly acted as president under the 25th Amendment: George H. W. Bush on July 13, 1985; Dick Cheney on June 29, 2002, and on July 21, 2007; and Kamala Harris on November 19, 2021.\n",
      "The persons who have served as vice president were born in or primarily affiliated with 27 states plus the District of Columbia. New York has produced the most of any state as eight have been born there and three others considered it their home state. Most vice presidents have been in their 50s or 60s and had political experience before assuming the office. Two vice presidents—George Clinton and John C. Calhoun—served under more than one president. Ill with tuberculosis and recovering in Cuba on Inauguration Day in 1853, William R. King, by an Act of Congress, was allowed to take the oath outside the United States. He is the only vice president to take his oath of office in a foreign country.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by net worth\n",
      "Summary: The list of presidents of the United States by net worth at peak varies greatly. Debt and depreciation often means that presidents' net worth is less than $0 at the time of death. Most presidents before 1845 were extremely wealthy, especially Andrew Jackson and George Washington. \t \n",
      "Presidents since 1929, when Herbert Hoover took office, have generally been wealthier than presidents of the late nineteenth and early twentieth centuries; with the exception of Harry S. Truman, all presidents since this time have been millionaires. These presidents have often received income from autobiographies and other writing. Except for Franklin D. Roosevelt and John F. Kennedy (both of whom died while in office), all presidents beginning with Calvin Coolidge have written autobiographies. In addition, many presidents—including Bill Clinton—have earned considerable income from public speaking after leaving office.The richest president in history may be Donald Trump. However, his net worth is not precisely known because the Trump Organization is privately held.Truman was among the poorest U.S. presidents, with a net worth considerably less than $1 million. His financial situation contributed to the doubling of the presidential salary to $100,000 in 1949. In addition, the presidential pension was created in 1958 when Truman was again experiencing financial difficulties. Harry and Bess Truman received the first Medicare cards in 1966 via the Social Security Act of 1965.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of presidents of the United States by home state\n",
      "Summary: These lists give the states of primary affiliation and of birth for each president of the United States.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `Joe Biden`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Joe Biden\n",
      "Summary: Joseph Robinette Biden Jr. (  BY-dən; born November 20, 1942) is an American politician who is the 46th and current president of the United States. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009.\n",
      "Born in Scranton, Pennsylvania, Biden moved with his family to Delaware in 1953. He graduated from the University of Delaware before earning his law degree from Syracuse University. He was elected to the New Castle County Council in 1970 and to the U.S. Senate in 1972. As a senator, Biden drafted and led the effort to pass the Violent Crime Control and Law Enforcement Act and the Violence Against Women Act. He also oversaw six U.S. Supreme Court confirmation hearings, including the contentious hearings for Robert Bork and Clarence Thomas. Biden ran unsuccessfully for the Democratic presidential nomination in 1988 and 2008. In 2008, Obama chose Biden as his running mate, and he was a close counselor to Obama during his two terms as vice president. In the 2020 presidential election, Biden and his running mate, Kamala Harris, defeated incumbents Donald Trump and Mike Pence. He became the oldest president in U.S. history, and the first to have a female vice president.\n",
      "As president, Biden signed the American Rescue Plan Act in response to the COVID-19 pandemic and subsequent recession. He signed bipartisan bills on infrastructure and manufacturing. He proposed the Build Back Better Act, which failed in Congress, but aspects of which were incorporated into the Inflation Reduction Act that he signed into law in 2022. Biden appointed Ketanji Brown Jackson to the Supreme Court. He worked with congressional Republicans to resolve the 2023 United States debt-ceiling crisis by negotiating a deal to raise the debt ceiling. In foreign policy, Biden restored America's membership in the Paris Agreement. He oversaw the complete withdrawal of U.S. troops from Afghanistan that ended the war in Afghanistan, during which the Afghan government collapsed and the Taliban seized control. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia and authorizing civilian and military aid to Ukraine. During the Israel–Hamas war, Biden announced military support for Israel, and condemned the actions of Hamas and other Palestinian militants as terrorism. In April 2023, Biden announced his candidacy for the Democratic nomination in the 2024 presidential election.\n",
      "\n",
      "Page: Family of Joe Biden\n",
      "Summary: Joe Biden, the 46th and current president of the United States, has family members who are prominent in law, education, activism and politics. Biden's immediate family became the first family of the United States on his inauguration on January 20, 2021. His immediate family circle was also the second family of the United States from 2009 to 2017, when Biden was vice president. Biden's family is mostly descended from the British Isles, with most of their ancestors coming from Ireland and England, and a smaller number descending from the French.Of Joe Biden's sixteen great-great-grandparents, ten were born in Ireland. He is descended from the Blewitts of County Mayo and the Finnegans of County Louth. One of Biden's great-great-great-grandfathers was born in Sussex, England, and emigrated to Maryland in the United States by 1820.\n",
      "\n",
      "Page: Presidency of Joe Biden\n",
      "Summary: Joe Biden's tenure as the 46th president of the United States began with his inauguration on January 20, 2021. Biden, a Democrat from Delaware who previously served as vice president for two terms under president Barack Obama, took office following his victory in the 2020 presidential election over Republican incumbent president Donald Trump. Upon his inauguration, he became the oldest president in American history, breaking the record set by his predecessor Trump. Biden entered office amid the COVID-19 pandemic, an economic crisis, and increased political polarization.On the first day of his presidency, Biden made an effort to revert President Trump's energy policy by restoring U.S. participation in the Paris Agreement and revoking the permit for the Keystone XL pipeline. He also halted funding for Trump's border wall, an expansion of the Mexican border wall. On his second day, he issued a series of executive orders to reduce the impact of COVID-19, including invoking the Defense Production Act of 1950, and set an early goal of achieving one hundred million COVID-19 vaccinations in the United States in his first 100 days.Biden signed into law the American Rescue Plan Act of 2021; a $1.9 trillion stimulus bill that temporarily established expanded unemployment insurance and sent $1,400 stimulus checks to most Americans in response to continued economic pressure from COVID-19. He signed the bipartisan Infrastructure Investment and Jobs Act; a ten-year plan brokered by Biden alongside Democrats and Republicans in Congress, to invest in American roads, bridges, public transit, ports and broadband access. Biden signed the Juneteenth National Independence Day Act, making Juneteenth a federal holiday in the United States. He appointed Ketanji Brown Jackson to the U.S. Supreme Court—the first Black woman to serve on the court. After The Supreme Court overturned Roe v. Wade, Biden took executive actions, such as the signing of Executive Order 14076, to preserve and protect women's health rights nationwide, against abortion bans in Republican led states. Biden proposed a significant expansion of the U.S. social safety net through the Build Back Better Act, but those efforts, along with voting rights legislation, failed in Congress. However, in August 2022, Biden signed the Inflation Reduction Act of 2022, a domestic appropriations bill that included some of the provisions of the Build Back Better Act after the entire bill failed to pass. It included significant federal investment in climate and domestic clean energy production, tax credits for solar panels, electric cars and other home energy programs as well as a three-year extension of Affordable Care Act subsidies. Biden signed the CHIPS and Science Act, bolstering the semiconductor and manufacturing industry, the Honoring our PACT Act, expanding health care for US veterans, and the Electoral Count Reform and Presidential Transition Improvement Act. In late 2022, Biden signed the Respect for Marriage Act, which repealed the Defense of Marriage Act and codified same-sex and interracial marriage in the United States. In response to the debt-ceiling crisis of 2023, Biden negotiated and signed the Fiscal Responsibility Act of 2023, which restrains federal spending for fiscal years 2024 and 2025, implements minor changes to SNAP and TANF, includes energy permitting reform, claws back some IRS funding and unspent money for COVID-19, and suspends the debt ceiling to January 1, 2025. Biden established the American Climate Corps and created the first ever White House Office of Gun Violence Prevention. On September 26, 2023, Joe Biden visited a United Auto Workers picket line during the 2023 United Auto Workers strike, making him the first US president to visit one.\n",
      "The foreign policy goal of the Biden administration is to restore the US to a \"position of trusted leadership\" among global democracies in order to address the challenges posed by Russia and China. In foreign policy, Biden completed the withdrawal of U.S. military forces from Afghanistan, declaring an end to nation-building efforts and shifting U.S. foreign policy toward strategic competition with China and, to a lesser extent, Russia. However, during the withdrawal, the Afghan government collapsed and the Taliban seized control, leading to Biden receiving bipartisan criticism. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia as well as providing Ukraine with over $100 billion in combined military, economic, and humanitarian aid. Biden also approved a raid which led to the death of Abu Ibrahim al-Hashimi al-Qurashi, the leader of the Islamic State, and approved a drone strike which killed Ayman Al Zawahiri, leader of Al-Qaeda. Biden signed AUKUS, an international security alliance, together with Australia and the United Kingdom. Biden called for the expansion of NATO with the addition of Finland and Sweden, and rallied NATO allies in support of Ukraine. During the 2023 Israel–Hamas war, Biden condemned Hamas and other Palestinian militants as terrorism and announced American military support for Israel; Biden also showed his support and sympathy towards Palestinians affected by the war, sent humanitarian aid, and brokered a four-day temporary pause and hostage exchange.\n",
      "Biden began his term with over 50% approval ratings; however, these fell significantly after the withdrawal from Afghanistan and remained low as the country experienced high inflation and rising gas prices. His age and mental fitness have also been a subject of discussion.\n",
      "\n",
      "Page: Cabinet of Joe Biden\n",
      "Summary: Joe Biden assumed office as President of the United States on January 20, 2021. The president has the authority to nominate members of his Cabinet to the United States Senate for confirmation under the Appointments Clause of the United States Constitution.\n",
      "Before confirmation and during congressional hearings, a high-level career member of an executive department heads this pre-confirmed cabinet on an acting basis. The Cabinet's creation was part of the transition of power following the 2020 United States presidential election.\n",
      "In addition to the 15 heads of executive departments, there are 10 Cabinet-level officials. Biden altered his cabinet structure, elevating the chair of the Council of Economic Advisers, director of the Office of Science and Technology Policy and ambassador to the United Nations as Cabinet-level positions. Biden initially removed the director of the Central Intelligence Agenc\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `Delaware`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Delaware\n",
      "Summary: Delaware (  DEL-ə-wair) is a state in the northeast and Mid-Atlantic regions of the United States. It borders Maryland to its south and west, Pennsylvania to its north, New Jersey to its northeast, and the Atlantic Ocean to its east. The state's name derives from the adjacent Delaware Bay, which in turn was named after Thomas West, 3rd Baron De La Warr, an English nobleman and the Colony of Virginia's first colonial-era governor.Delaware occupies the northeastern portion of the Delmarva Peninsula, and some islands and territory within the Delaware River. It is the 2nd smallest and 6th least populous state, but also the 6th most densely populated. Delaware's most populous city is Wilmington, and the state's capital is Dover, the 2nd most populous city in Delaware. The state is divided into three counties, the fewest number of counties of any of the 50 U.S. states; from north to south, the three counties are: New Castle County, Kent County, and Sussex County.\n",
      "The southern two counties, Kent and Sussex counties, historically have been predominantly agrarian economies. New Castle is more urbanized and is considered part of the Delaware Valley metropolitan statistical area that surrounds and includes Philadelphia, the nation's 6th most populous city. Delaware is considered part of the Southern United States by the U.S. Census Bureau, but the state's geography, culture, and history are a hybrid of the Mid-Atlantic and Northeastern regions of the country.Before Delaware coastline was explored and developed by Europeans in the 16th century, the state was inhabited by several Native Americans tribes, including the Lenape in the north and Nanticoke in the south. The state was first colonized by Dutch traders at Zwaanendael, near present-day Lewes, Delaware, in 1631.\n",
      "Delaware was one of the Thirteen Colonies that participated in the American Revolution and American Revolutionary War, in which the American Continental Army, led by George Washington, defeated the British, ended British colonization and establishing the United States as a sovereign and independent nation.\n",
      "On December 7, 1787, Delaware was the first state to ratify the Constitution of the United States, earning it the nickname \"The First State\".Since the turn of the 20th century, Delaware has become an onshore corporate haven whose corporate laws are deemed appealing to corporations; over half of all New York Stock Exchange-listed corporations and over three-fifths of the Fortune 500 is legally incorporated in the state.\n",
      "\n",
      "Page: Delaware City, Delaware\n",
      "Summary: Delaware City is a city in New Castle County, Delaware, United States. The population was 1,885 as of 2020. It is a small port town on the eastern terminus of the Chesapeake and Delaware Canal and is the location of the Forts Ferry Crossing to Fort Delaware on Pea Patch Island.\n",
      "\n",
      "\n",
      "\n",
      "Page: University of Delaware\n",
      "Summary: The University of Delaware (colloquially known as UD or Delaware) is a privately governed, state-assisted land-grant research university located in Newark, Delaware. UD is the largest university in Delaware. It offers three associate's programs, 148 bachelor's programs, 121 master's programs (with 13 joint degrees), and 55 doctoral programs across its eight colleges. The main campus is in Newark, with satellite campuses in Dover, Wilmington, Lewes, and Georgetown. It is considered a large institution with approximately 18,200 undergraduate and 4,200 graduate students. It is a privately governed university which receives public funding for being a land-grant, sea-grant, and space-grant state-supported research institution.UD is classified among \"R1: Doctoral Universities – Very high research activity\". According to the National Science Foundation, UD spent $186 million on research and development in 2018, ranking it 119th in the nation.  It is recognized with the Community Engagement Classification by the Carnegie Foundation for the Advancement of Teaching.UD students, alumni, and sports teams are known as the \"Fightin' Blue Hens\", more commonly shortened to \"Blue Hens\", and the school colors are Delaware blue and gold. UD sponsors 21 men's and women's NCAA Division-I sports teams and have competed in the Colonial Athletic Association (CAA) since 2001.\n",
      "\n",
      "Page: Delaware River\n",
      "Summary: The Delaware River is a major river in the Mid-Atlantic region of the United States and is the longest free-flowing (undammed) river in the Eastern United States. From the meeting of its branches in Hancock, New York, the river flows for 282 miles (454 km) along the borders of New York, Pennsylvania, New Jersey, and Delaware, before emptying into Delaware Bay.\n",
      "The river has been recognized by the National Wildlife Federation as one of the country's Great Waters and has been called the \"Lifeblood of the Northeast\" by American Rivers. Its watershed drains an area of 13,539 square miles (35,070 km2) and provides drinking water for 17 million people, including half of New York City via the Delaware Aqueduct.\n",
      "The Delaware River has two branches that rise in the Catskill Mountains of New York: the West Branch at Mount Jefferson in Jefferson, Schoharie County, and the East Branch at Grand Gorge, Delaware County. The branches merge to form the main Delaware River at Hancock, New York. Flowing south, the river remains relatively undeveloped, with 152 miles (245 km) protected as the Upper, Middle, and Lower Delaware National Scenic Rivers. At Trenton, New Jersey, the Delaware becomes tidal, navigable, and significantly more industrial. This section forms the backbone of the Delaware Valley metropolitan area, serving the port cities of Philadelphia, Camden, New Jersey, and Wilmington, Delaware. The river flows into Delaware Bay at Liston Point, 48 miles (77 km) upstream of the bay's outlet to the Atlantic Ocean between Cape May and Cape Henlopen.\n",
      "Before the arrival of European settlers, the river was the homeland of the Lenape native people. They called the river Lenapewihittuk, or Lenape River, and Kithanne, meaning the largest river in this part of the country.In 1609, the river was visited by a Dutch East India Company expedition led by Henry Hudson. Hudson, an English navigator, was hired to find a western route to Cathay (China), but his encounters set the stage for Dutch colonization of North America in the 17th century. Early Dutch and Swedish settlements were established along the lower section of the river and Delaware Bay. Both colonial powers called the river the South River (Zuidrivier), compared to the Hudson River, which was known as the North River. After the English expelled the Dutch and took control of the New Netherland colony in 1664, the river was renamed Delaware after Sir Thomas West, 3rd Baron De La Warr, an English nobleman and the Virginia colony's first royal governor, who defended the colony during the First Anglo-Powhatan War.\n",
      "\n",
      "Page: Lenape\n",
      "Summary: The Lenape (English: , , ; Lenape languages: [lənaːpe]), also called the Lenni Lenape and Delaware people, are an Indigenous people of the Northeastern Woodlands, who live in the United States and Canada.The Lenape's historical territory includes present-day northeastern Delaware, all of New Jersey, the eastern Pennsylvania regions of the Lehigh Valley and Northeastern Pennsylvania, and New York Bay, western Long Island, and the lower Hudson Valley in New York state. Today they are based in Oklahoma, Wisconsin, and Ontario.\n",
      "During the last decades of the 18th century, European settlers and the effects of the American Revolutionary War displaced most Lenape from their homelands and pushed them north and west. In the 1860s, under the Indian removal policy, the U.S. federal government relocated most Lenape remaining in the Eastern United States to the Indian Territory and surrounding regions. Lenape people currently belong to the Delaware Nation and Delaware Tribe of Indians in Oklahoma, the Stockbridge–Munsee Community in Wisconsin, and the Munsee-Delaware Nation, Moravian of the Thames First Nation, and Delaware of Six Nations in Ontario.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Wikipedia` with `American Goldfinch`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\User\\.virtualenvs\\Tutorials_from_Langchain-HvUJzvlK\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mPage: American goldfinch\n",
      "Summary: The American goldfinch (Spinus tristis) is a small North American bird in the finch family. It is migratory, ranging from mid-Alberta to North Carolina during the breeding season, and from just south of the Canada–United States border to Mexico during the winter.\n",
      "The only finch in its subfamily to undergo a complete molt, the American goldfinch displays sexual dichromatism: the male is a vibrant yellow in the summer and an olive color during the winter, while the female is a dull yellow-brown shade which brightens only slightly during the summer. The male displays brightly colored plumage during the breeding season to attract a mate.\n",
      "The American goldfinch is a granivore and adapted for the consumption of seedheads, with a conical beak to remove the seeds and agile feet to grip the stems of seedheads while feeding. It is a social bird and will gather in large flocks while feeding and migrating. It may behave territorially during nest construction, but this aggression is short-lived. Its breeding season is tied to the peak of food supply, beginning in late July, which is relatively late in the year for a finch. This species is generally monogamous and produces one brood each year.\n",
      "Human activity has generally benefited the American goldfinch. It is often found in residential areas because it is attracted to bird feeders, which increase its survival rate in these areas. Deforestation also creates open meadow areas, which are its preferred habitat.\n",
      "\n",
      "Page: The Goldfinch (film)\n",
      "Summary: The Goldfinch is a 2019 American drama film directed by John Crowley. It was written by Peter Straughan, who adapted the 2013 novel The Goldfinch by Donna Tartt. It stars Ansel Elgort as Theodore Decker, whose life changes after his mother dies in a terrorist bombing at a museum and a dying man convinces him to take a famous painting called The Goldfinch from the museum. Oakes Fegley, Aneurin Barnard, Finn Wolfhard, Sarah Paulson, Luke Wilson, Jeffrey Wright, and Nicole Kidman appear in supporting roles.\n",
      "The novel's film rights were sold to Warner Bros. and RatPac Entertainment in July 2014, with ICM Partners brokering the deal. Two years later, Crowley was hired to direct the film adaptation, and Elgort was selected to portray the lead role. Most of the remaining cast joined from October 2017 to January 2018. Filming began in New York City in January 2018 and moved to Albuquerque in April 2018 for the rest of the production.\n",
      "The Goldfinch premiered at the 2019 Toronto International Film Festival and was theatrically released in the United States on September 13, 2019, by Warner Bros. Pictures. It was a box-office bomb, with estimated losses for the studio as high as $50 million, and received generally negative reviews that criticised the plot and narrative, though the cinematography and performances received praise. Donna Tartt reportedly hated the adaptation to the point of firing her longtime agent over it, and making it clear she would not sell the rights to any of her work for films again.\n",
      "\n",
      "Page: The Goldfinch (novel)\n",
      "Summary: The Goldfinch is a novel by the American author Donna Tartt. It won the 2014 Pulitzer Prize for Fiction, among other honors. Published in 2013, it was Tartt's first novel since The Little Friend in 2002.The Goldfinch centers on 13-year-old Theodore Decker, and the dramatic changes his life undergoes after he survives a terrorist attack at the Metropolitan Museum of Art that kills his mother and results in him coming into possession of Carel Fabritius's painting The Goldfinch.\n",
      "\n",
      "Page: Lesser goldfinch\n",
      "Summary: The lesser goldfinch (Spinus psaltria) is a very small songbird of the Americas. Together with its relatives the American goldfinch and Lawrence's goldfinch, it forms the New World goldfinch clade in the genus Spinus.\n",
      "As is the case for all three New World goldfinches (and some of their siskin relatives), lesser goldfinch males have a black forehead, which females lack. Males in this species vary strikingly in back color across their range, from green in western North America to black from Texas south to South America. Five subspecies are often recognized.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe current US president is Joe Biden. His home state is Delaware. The state bird of Delaware is the American goldfinch (Spinus tristis). The scientific name for the American goldfinch is Spinus tristis.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Who is the current US president? What's their home state? What's their home state's bird? What's that bird's scientific name?\",\n",
       " 'output': 'The current US president is Joe Biden. His home state is Delaware. The state bird of Delaware is the American goldfinch (Spinus tristis). The scientific name for the American goldfinch is Spinus tristis.'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def condense_prompt(prompt: ChatPromptValue) -> ChatPromptValue:\n",
    "    messages = prompt.to_messages()\n",
    "    num_tokens = llm.get_num_tokens_from_messages(messages)\n",
    "    ai_function_messages = messages[2:]\n",
    "    while num_tokens > 4_000:\n",
    "        ai_function_messages = ai_function_messages[2:]\n",
    "        num_tokens = llm.get_num_tokens_from_messages(\n",
    "            messages[:2] + ai_function_messages\n",
    "        )\n",
    "    messages = messages[:2] + ai_function_messages\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | condense_prompt\n",
    "    | llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Who is the current US president? What's their home state? What's their home state's bird? What's that bird's scientific name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b66e44fdf5203d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
